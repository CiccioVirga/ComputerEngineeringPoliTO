# Esame 2022-10-26

## Domanda 1

Si illustrino le differenze tra stack e heap. Insieme alle differenze, indicare per i seguenti costrutti Rust, in modo dettagliato, dove si trovano i dati che li compongono: 

- `Box<[T]>`
- `RefCell<T>` 
- `&[T]`

<details>
<summary>Soluzione</summary>

> Soluzione non verificata

La differenza tra stack e heap è la modalità con le quali questi vengono utilizzati e la metodologia secondo cui i dati vengono eliminati:

- lo stack utilizza una struttura dati a pila di tipo LIFO. Le varabili presenti nello stack vengono liberate, se non richiesto esplicitamente prima, ogni qual volta queste escano dal proprio scope (quindi la graffa del blocco che le definisce).
- L'heap ha una struttura di memorizzazione ad albero, dove i dati non vengono liberati all'uscita dallo scope ma su richiesta esplicita da parte del programmatore, motivo per cui è molto importante la gestione della memoria in linguaggi come C/C++ e Rust. Questo ci consente di restituire valori dalle funzioni che sennò verrebbero automaticamente eliminati dal compilatore.

Per quanto riguarda gli smart pointer:

- `Box<[T]>`: Nello stack è presente un puntatore al primo elemento del vettore e un attributo len che indica il numero di valori, nell'heap è presente il vettore.
- `RefCell<T>`: nello stack è presente un campo borrow contenente il campo borrow e il dato T. 
- `&[T]`: riferimento a una slice che può trovarsi sia nello stack che nell'heap. Nello stack sarà presente un puntatore al dato (heap o stack) e un valore len che indica la quantità di dati presenti.

</details>

## Domanda 2

> Domanda 2 mancante

## Domanda 3

In riferimento a programmi multi-thread, si indichi se la natura della loro esecuzione sia deterministica o meno a priori. Si produca un esempio che dimostri tale affermazione.

<details>
<summary>Soluzione</summary>

La programmazione multithread (senza sincronizzazione opportuna) non è deterministica si possono ottenere comportamenti imprevedibili ed è la ragione per cui è necessario utilizzare adeguatamente costrutti di sincronizzazione in modo da evitare situazioni di deadlock.

Un esempio che dimostra l'imprevedibilità di un approccio multi-thread è quello dell'**interferenza**, possiamo immaginare una istruzione apparentemente innocua come un increment: a++. Nonostante sembri una istruzione sola (atomica) di fatto questa si traduce in due istruzioni: `temp=a; a=temp+1;`. Il problema di questo, che porterà poi alla conclusione che non si possono lasciare operazioni in stati intermedi e che non si può fare accesso in lettura/scrittura da più thread contemporaneamente (race condition) è ricollegabile di fatto al modello gerarchico delle memorie dove essendoci cache a diversi livelli es fino al livello 2 non comunicano tra i core, ci saranno dei tempi di propagazione e quindi di visibilità tra diversi thread di un valore in memoria. Quindi quello che può succedere è che un thread salvi il valore di a in temp in una sua locazione di memoria quindi, e fintanto che questo cambiamento sia visibile da un altro thread che vuole operare su quel valore quello che può succedere è che lo scheduler freeze questo primo thread e lo lasci dormiente intanto sveglia un altro thread che fa la stessa operazione salva in un indirizzo di memoria a e poi fa gli increment, questo magari lo fa un pò di volte se sono chiamati più increment. Ma quando viene svegliato il primo thread di fatto riprende la sua esecuzione e mette in a il valore del temp che lui aveva incrementato di 1; quindi stampando il valore sembra che sia tornato indietro. Dunque l'interferenza è uno degli esempi di non determinismo che si possono avere senza i costrutti di sincronizzazione. Un esempio in Rust (che non permette a++) è quello di Rc che avendo i contatori non atomici dei riferimenti (Strong e Weak) non è ne Send ne Sync, infatti per questo è stato creato Arc con i contatori atomici che permettono increment e decrement atomici (operazioni più costose ma necessarie nel multithread).

</details>

## Domanda 4

Un componente con funzionalità di cache permette di ottimizzare il comportamento di un sistema riducendo il numero di volte in cui una funzione è invocata, tenendo traccia dei risultati da essa restituiti a fronte di un particolare dato in ingresso. Per generalità, si assuma che la funzione accetti un dato di tipo generico `K` e restituisca un valore di tipo generico `V`.

Il componente offre un unico metodo `get(...)` che prende in ingresso due parametri, il valore `k` (di tipo K, clonabile) del parametro e la funzione f (di tipo K -> V) responsabile della sua trasformazione, e restituisce uno smart pointer clonabile al relativo valore.

Se, per una determinata chiave `k`, non è ancora stato calcolato il valore corrispondente, la funzione viene invocata e ne viene restituito il risultato; altrimenti viene restituito il risultato già trovato.

Il componente cache deve essere thread-safe perché due o più thread possono richiedere contemporaneamente il valore di una data chiave: quando questo avviene e il dato non è ancora presente, la chiamata alla funzione dovrà essere eseguita nel contesto di UN SOLO thread, mentre gli altri dovranno aspettare il risultato in corso di elaborazione, SENZA CONSUMARE cicli macchina.

Si implementi tale componente a scelta nei linguaggi C++ o Rust.

<!-- 
<details>
<summary>Soluzione</summary>

</details>
-->